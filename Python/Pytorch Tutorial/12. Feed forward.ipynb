{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets, models, transforms\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Hyper parameters\r\n",
    "input_size = 784   # The image size = 28 x 28 = 784\r\n",
    "hidden_size = 100\r\n",
    "num_classes = 10\r\n",
    "num_epochs = 2\r\n",
    "batch_size = 100\r\n",
    "learning_rate = 0.001"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# MNIST dataset\r\n",
    "train_dataset = datasets.MNIST(root='./data',\r\n",
    "                               train=True,\r\n",
    "                               transform=transforms.ToTensor(),\r\n",
    "                               download=False)\r\n",
    "\r\n",
    "test_dataset = datasets.MNIST(root='./data',\r\n",
    "                              train=False,\r\n",
    "                              transform=transforms.ToTensor(),\r\n",
    "                              download=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\r\n",
    "                                           batch_size=batch_size,\r\n",
    "                                           shuffle=True)\r\n",
    "\r\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\r\n",
    "                                          batch_size=batch_size,\r\n",
    "                                          shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "examples = iter(train_loader)\r\n",
    "samples, labels = next(examples)\r\n",
    "print(samples.shape, labels.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "for i in range(6):\r\n",
    "    plt.subplot(2, 3, i+1)\r\n",
    "    plt.imshow(samples[i][0], cmap='gray')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "class NeuralNet(nn.Module):\r\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\r\n",
    "        super(NeuralNet, self).__init__()\r\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        out = self.l1(x)\r\n",
    "        out = self.relu(out)\r\n",
    "        out = self.l2(out)\r\n",
    "        return out\r\n",
    "\r\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Loss and optimizer\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Train the model\r\n",
    "n_total_steps = len(train_loader)\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    for i, (images, labels) in enumerate(train_loader):\r\n",
    "        # Reshape images to (batch_size, input_size)\r\n",
    "        images = images.reshape(-1, 28*28).to(device)\r\n",
    "        labels = labels.to(device)\r\n",
    "        \r\n",
    "        # Forward pass\r\n",
    "        outputs = model(images)\r\n",
    "        loss = criterion(outputs, labels)\r\n",
    "        \r\n",
    "        # Backward and optimize\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        if (i+1) % 100 == 0:\r\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \r\n",
    "                   .format(epoch+1, num_epochs, i+1, n_total_steps, loss.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.2972\n",
      "Epoch [1/2], Step [200/600], Loss: 0.1699\n",
      "Epoch [1/2], Step [300/600], Loss: 0.1114\n",
      "Epoch [1/2], Step [400/600], Loss: 0.0865\n",
      "Epoch [1/2], Step [500/600], Loss: 0.3334\n",
      "Epoch [1/2], Step [600/600], Loss: 0.1918\n",
      "Epoch [2/2], Step [100/600], Loss: 0.1013\n",
      "Epoch [2/2], Step [200/600], Loss: 0.1004\n",
      "Epoch [2/2], Step [300/600], Loss: 0.0707\n",
      "Epoch [2/2], Step [400/600], Loss: 0.2622\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1565\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1758\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Test the model\r\n",
    "with torch.no_grad():\r\n",
    "    n_correct = 0\r\n",
    "    n_samples = 0\r\n",
    "    for images, labels in test_loader:\r\n",
    "        images = images.reshape(-1, 28*28).to(device)\r\n",
    "        labels = labels.to(device)\r\n",
    "        outputs = model(images)\r\n",
    "\r\n",
    "        _, predictions = torch.max(outputs.data, 1)\r\n",
    "        n_samples += labels.size(0)\r\n",
    "        n_correct += (predictions == labels).sum().item()\r\n",
    "\r\n",
    "    print('Accuracy of the model on the test images: {} %'.format(100 * n_correct / n_samples))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the model on the test images: 95.69 %\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "b8d0ede588d15b89434cd61d7894b7bb4dbe752a5f2a1bd905f19276a50935ce"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}